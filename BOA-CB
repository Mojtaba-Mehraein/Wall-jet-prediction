import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from catboost import CatBoostRegressor, Pool
from skopt import gp_minimize
from skopt.space import Integer, Real
from skopt.utils import use_named_args

# For Jupyter notebook display
%matplotlib inline

# -------------------------
# Load Data
# -------------------------
data = pd.read_csv("Udata.csv")
X = data.iloc[:, 0:5].values   # Features: X, Y, TWR, ER, Re
y = data.iloc[:, 5].values     # Label: U

# Split data (70% train, 30% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# -------------------------
# Define Search Space for Bayesian Optimization
# -------------------------
space  = [
    Integer(3, 10, name="depth"),                # Tree depth
    Real(0.01, 0.3, prior="log-uniform", name="learning_rate"), # Learning rate
    Real(1, 10, prior="log-uniform", name="l2_leaf_reg")        # L2 regularization
]

# -------------------------
# Objective Function
# -------------------------
@use_named_args(space)
def objective(**params):
    model = CatBoostRegressor(
        depth=params["depth"],
        learning_rate=params["learning_rate"],
        l2_leaf_reg=params["l2_leaf_reg"],
        iterations=300,
        silent=True,
        random_seed=42
    )
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    return mean_squared_error(y_test, preds)   # minimize MSE

# -------------------------
# Run Bayesian Optimization
# -------------------------
res = gp_minimize(objective, space, n_calls=120, random_state=42, n_initial_points=100)

best_depth = res.x[0]
best_lr = res.x[1]
best_l2 = res.x[2]

print("\nBest Parameters Found by Bayesian Optimization:")
print(f"Depth: {best_depth}, Learning Rate: {best_lr:.4f}, L2 Leaf Reg: {best_l2:.4f}")
print("Best MSE:", res.fun)

# -------------------------
# Train Final Model with Best Parameters
# -------------------------
final_model = CatBoostRegressor(
    depth=best_depth,
    learning_rate=best_lr,
    l2_leaf_reg=best_l2,
    iterations=500,
    silent=True,
    random_seed=42
)
final_model.fit(X_train, y_train)

# Predict on training and testing data
y_train_pred = final_model.predict(X_train)
y_test_pred = final_model.predict(X_test)

# -------------------------
# Evaluation
# -------------------------
mse_train = mean_squared_error(y_train, y_train_pred)
r2_train = r2_score(y_train, y_train_pred)

mse_test = mean_squared_error(y_test, y_test_pred)
r2_test = r2_score(y_test, y_test_pred)

print("\nFinal Model Performance (CatBoost with Bayesian Optimization):")
print(f"Train -> MSE: {mse_train:.4f}, R²: {r2_train:.4f}")
print(f"Test  -> MSE: {mse_test:.4f}, R²: {r2_test:.4f}")

# -------------------------
# Create Excel File with Two Sheets
# -------------------------
# Create DataFrames for training and testing data
train_df = pd.DataFrame({
    'Measured_Training': y_train,
    'Predicted_Training': y_train_pred
})

test_df = pd.DataFrame({
    'Measured_Testing': y_test,
    'Predicted_Testing': y_test_pred
})

# Write to Excel file with two sheets
with pd.ExcelWriter('BO-CB_results.xlsx') as writer:
    train_df.to_excel(writer, sheet_name='Training_Data', index=False)
    test_df.to_excel(writer, sheet_name='Testing_Data', index=False)

print("\nExcel file 'BO-CB_results.xlsx' created with training and testing results")
